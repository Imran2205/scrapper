{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "from mantis_scrapper.mantis_scrapper.spiders.mantis_spider import MantisSpider\n",
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n",
      "150000\n"
     ]
    }
   ],
   "source": [
    "print(sys.getrecursionlimit())\n",
    "sys.setrecursionlimit(150000)\n",
    "print(sys.getrecursionlimit())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "news_web_tag_info = {\n",
    "    'fiercewireless': {\n",
    "        'url': 'https://www.fiercewireless.com',\n",
    "        'tags': [\n",
    "            [('div', 'id', 'article-tags-row'), ('a', 'class', 'tag')],\n",
    "            [('div', 'id', 'article-tags-bottom-row'), ('a', 'class', 'tag')]\n",
    "        ],\n",
    "        'date': [\n",
    "            [('span', 'class', 'date')]\n",
    "        ]\n",
    "    },\n",
    "    'macrumors': {\n",
    "        'url': 'https://www.macrumors.com',\n",
    "        'tags': [\n",
    "            [('div', 'class', 'linkback'), ('a', '', '')]\n",
    "        ],\n",
    "        'date': [\n",
    "            [('time', '', '')]\n",
    "        ]\n",
    "    },\n",
    "    'macworld': {\n",
    "        'url': 'https://www.macworld.com',\n",
    "        'tags': [],\n",
    "        'date': [\n",
    "            [('span', 'class', 'posted-on')]\n",
    "        ]\n",
    "    },\n",
    "    'digitimes': {\n",
    "        'url': 'https://www.digitimes.com',\n",
    "        'tags': [\n",
    "            [('div', 'class', 'tag'), ('a', 'class', 'label grey')]\n",
    "        ],\n",
    "        'date': [\n",
    "            [('span', 'class', 'date'), ('time', '', '')]\n",
    "        ]\n",
    "    },\n",
    "    'lightreading': {\n",
    "        'url': 'https://www.lightreading.com',\n",
    "        'tags': [],\n",
    "        'date': [\n",
    "            [('span', 'class', 'date'), ('time', '', '')]\n",
    "        ]\n",
    "    }\n",
    "    ,\n",
    "    'eetimes': {\n",
    "        'url': 'https://www.eetimes.com',\n",
    "        'tags': [\n",
    "            [('div', 'class', 'post-tags'), ('span', 'itemprop', 'keywords'), ('a', 'rel', 'tag')]\n",
    "        ],\n",
    "        'date': [\n",
    "            [('span', 'class', 'articleHeader-date')]\n",
    "        ]\n",
    "    }\n",
    "    ,\n",
    "    'seekingalpha': {\n",
    "        'url': 'https://seekingalpha.com',\n",
    "        'tags': [],\n",
    "        'date': [\n",
    "            [('span', 'class', 'oT-Ov oT-ji ag-gn')]\n",
    "        ]\n",
    "    },\n",
    "    'gsma': {\n",
    "        'url': 'https://www.gsma.com',\n",
    "        'tags': [],\n",
    "        'date': [\n",
    "            [('p', 'class', 'post-date')]\n",
    "        ]\n",
    "    },\n",
    "    'wsj': {\n",
    "        'url': 'https://www.wsj.com',\n",
    "        'tags': [],\n",
    "        'date': [\n",
    "            [('time', '', '')]\n",
    "        ]\n",
    "    }\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "news_webs = [\n",
    "    'https://www.fiercewireless.com',\n",
    "    'https://www.bloomberg.com'\n",
    "]\n",
    "\n",
    "news_webs = news_webs[1:]\n",
    "\n",
    "key_words = [\n",
    "    \"smartphone\", \"smartphone technology\",\n",
    "    \"wearables\", \"smart watch\", \"smart glasses\", \"ar/vr headsets\", \"ar headsets\", \"vr headsets\",\n",
    "    \"iphone\", \"android smartphone\",\n",
    "    \"apple\", \"samsung\", \"xiaomi\", \"oppo\", \"vivo\",\n",
    "    \"qualcomm\", \"nxp\", \"mediaTek\", \"cirrus logic\", \"skyworks\", \"qorvo\", \"broadcom\", \"sony\", \"murata\",\n",
    "    \"wifi\", \"cellular\", \"5g\", \"6g\", \"uwb\", \"nfc\",\n",
    "    \"apple pay\", \"android pay\",\n",
    "    \"magsafe\", \"wireless charging\",\n",
    "    \"power management\", \"battery management\",\n",
    "    \"envelope tracker\",\n",
    "    \"rf front end\", \"transceiver\", \"modem\",\n",
    "    \"mmwave\", \"fr2\", \"fr3\",\n",
    "    \"oled display\", \"uled\", \"ltpo\", \"display driver ic\",\n",
    "    \"smartphone camera\", \"image sensing\", \"3d sensing\", \"camera\",\n",
    "    \"smart audio\",\n",
    "    \"haptics\",\n",
    "    \"satellite to smartphone connectivity\"\n",
    "]\n",
    "\n",
    "WINDOW_SIZE = \"600,400\"\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--window-size=%s\" % WINDOW_SIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "all_urls = []\n",
    "scrapped_links = []\n",
    "visited_links = []"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# url = news_webs[0]\n",
    "#\n",
    "# if url.endswith('/'):\n",
    "#     url = url[:-1]\n",
    "#\n",
    "# print(\"loading....\", url)\n",
    "# driver = webdriver.Chrome(\n",
    "#     executable_path=r'C:\\chromedriver.exe',\n",
    "#     chrome_options=chrome_options\n",
    "# )\n",
    "# driver.get(url)\n",
    "# time.sleep(20)\n",
    "# driver.find_element(By.CLASS_NAME, 'block-quartz-apifirst').click()\n",
    "# driver.find_element(By.CLASS_NAME, 'search-wrapper').click()\n",
    "# search_form = driver.find_element(By.CLASS_NAME, 'search-form')\n",
    "# search_form.find_element(By.NAME, 'fulltext_search').send_keys('smartphone')\n",
    "# search_form.find_element(By.CLASS_NAME, 'search-modal-submit').click()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def link_parser(web_links, out_file_name, url_info):\n",
    "    for count, url in enumerate(web_links):\n",
    "        if url.endswith('/'):\n",
    "            url = url[:-1]\n",
    "        if url in scrapped_links or url in visited_links:\n",
    "            if len(web_links) > 1:\n",
    "                print(\"skipping already visited: \", url)\n",
    "                continue\n",
    "        print(\"loading....\", url)\n",
    "        driver = webdriver.Chrome(\n",
    "            executable_path=r'C:\\chromedriver.exe',\n",
    "            chrome_options=chrome_options\n",
    "        )\n",
    "        driver.get(url)\n",
    "        # with open(\"visited_urls.txt\", 'a') as fb:\n",
    "        #     fb.write(url + \"\\n\")\n",
    "        #     visited_links.append(url)\n",
    "        html = driver.page_source\n",
    "\n",
    "        driver.close()\n",
    "        driver.quit()\n",
    "\n",
    "        time.sleep(10)\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        date = 'n/a'\n",
    "        if len(url.split('/')) > 4:\n",
    "            tags_list = []\n",
    "            key_word_match = False\n",
    "            matched_keys = []\n",
    "            if url_info['tags']:\n",
    "                for way in url_info['tags']:\n",
    "                    current_pos = soup\n",
    "                    for i, indnt in enumerate(way):\n",
    "                        if i == len(way) - 1:\n",
    "                            current_pos = current_pos.find_all(indnt[0], {indnt[1]: indnt[-1]})\n",
    "                        else:\n",
    "                            current_pos = current_pos.find_all(indnt[0], {indnt[1]: indnt[-1]})[0]\n",
    "\n",
    "                    for tag in current_pos:\n",
    "                        if tag and tag not in tags_list:\n",
    "                            tags_list.append(tag.text)\n",
    "                            if tag.text.lower() in key_words:\n",
    "                                key_word_match = True\n",
    "                                matched_keys.append(tag.text)\n",
    "            else:\n",
    "                for tag in key_words:\n",
    "                    if tag.replace(' ', '-') in url.lower():\n",
    "                        key_word_match = True\n",
    "                        matched_keys.append(tag)\n",
    "                        tags_list.append(tag)\n",
    "            if key_word_match:\n",
    "                for way in url_info['date']:\n",
    "                    current_pos = soup\n",
    "                    for i, indnt in enumerate(way):\n",
    "                        current_pos = current_pos.find_all(indnt[0], {indnt[1]: indnt[-1]})[0]\n",
    "\n",
    "                if len(current_pos) > 0:\n",
    "                    date = current_pos[0].text\n",
    "                    # print(date)\n",
    "                with open(out_file_name, 'a') as fa:\n",
    "                    fa.write(f\"{url} | {date} | {';'.join(matched_keys)} | {';'.join(tags_list)} \\n\")\n",
    "                    scrapped_links.append(url)\n",
    "\n",
    "        urls = []\n",
    "        for link in soup.find_all('a'):\n",
    "            link_ = link.get('href')\n",
    "            if link_:\n",
    "                if not link_.startswith('https://www.'):\n",
    "                    if not 'www.' in link_:\n",
    "                        base_url = \"https://\" + url.split('//')[1].split('/')[0]\n",
    "                        link_ = base_url + link_\n",
    "                    else:\n",
    "                        if link_.startswith(\"/\"):\n",
    "                            link_ = link_[1:]\n",
    "                        link_ = \"https://\" + link_\n",
    "                website = \"https://\" + link_.split('//')[1].split('/')[0]\n",
    "                # print(website, link_)\n",
    "                if website not in news_webs:\n",
    "                    continue\n",
    "                if link_ in all_urls or link_ in scrapped_links or link_ in visited_links:\n",
    "                    continue\n",
    "                urls.append(link_)\n",
    "                all_urls.append(link_)\n",
    "\n",
    "        link_parser(urls, out_file_name, url_info)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading.... https://www.bloomberg.com\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_228\\3376104967.py:10: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_228\\3376104967.py:10: DeprecationWarning: use options instead of chrome_options\n",
      "  driver = webdriver.Chrome(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.bloomberg.com https://www.bloomberg.com/feedback\n",
      "https://www.bloomberg.com https://www.bloomberg.com/notices/tos\n",
      "https://www.bloomberg.com https://www.bloomberg.com/notices/tos\n",
      "https://www.bloomberg.com https://www.bloomberg.com/feedback\n"
     ]
    }
   ],
   "source": [
    "file_name_out = \"matched_urls_all.txt\"\n",
    "\n",
    "if os.path.exists(file_name_out):\n",
    "    with open(file_name_out, 'r') as fao:\n",
    "        scrapped_links = [x.split('|')[0].strip() for x in fao.readlines()]\n",
    "else:\n",
    "    with open(file_name_out, 'w') as fao:\n",
    "        fao.write('')\n",
    "# if os.path.exists(\"visited_urls.txt\"):\n",
    "#     with open(\"visited_urls.txt\", 'r') as fbo:\n",
    "#         visited_links = [x.replace('\\n', '').strip() for x in fbo.readlines()]\n",
    "for web in news_webs:\n",
    "    info = news_web_tag_info[web.split('.')[1]]\n",
    "    link_parser([web], out_file_name=file_name_out, url_info=info)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open('all_urls.txt', 'w') as f:\n",
    "    f.write(\"\\n\".join(all_urls))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}